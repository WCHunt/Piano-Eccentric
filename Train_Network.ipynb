{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JKn8ergO-ESY"},"outputs":[],"source":["!pip install music21 pretty_midi keras-self-attention"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"LLcV3R-b-FoX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683871591087,"user_tz":420,"elapsed":2349182,"user":{"displayName":"William","userId":"06258725020209691855"}},"outputId":"93122a71-2725-459e-9b6e-7adb2014616f"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","105/105 [==============================] - 77s 596ms/step - loss: 0.8808 - val_loss: 0.1795\n","Epoch 2/20\n","105/105 [==============================] - 59s 563ms/step - loss: 0.8055 - val_loss: 0.1637\n","Epoch 3/20\n","105/105 [==============================] - 59s 565ms/step - loss: 0.8003 - val_loss: 0.1413\n","Epoch 4/20\n","105/105 [==============================] - 59s 567ms/step - loss: 0.7816 - val_loss: 0.2001\n","Epoch 5/20\n","105/105 [==============================] - 59s 564ms/step - loss: 0.7801 - val_loss: 0.1840\n","Epoch 6/20\n","105/105 [==============================] - 60s 567ms/step - loss: 0.7664 - val_loss: 0.1420\n","Epoch 7/20\n","105/105 [==============================] - 58s 555ms/step - loss: 0.7734 - val_loss: 0.1875\n","Epoch 8/20\n","105/105 [==============================] - 58s 555ms/step - loss: 0.7703 - val_loss: 0.1564\n","Epoch 9/20\n","105/105 [==============================] - 58s 555ms/step - loss: 0.7719 - val_loss: 0.1471\n","Epoch 10/20\n","105/105 [==============================] - 58s 554ms/step - loss: 0.7688 - val_loss: 0.1791\n","Epoch 11/20\n","105/105 [==============================] - 58s 556ms/step - loss: 0.7682 - val_loss: 0.1840\n","Epoch 12/20\n","105/105 [==============================] - 58s 554ms/step - loss: 0.7677 - val_loss: 0.1627\n","Epoch 13/20\n","105/105 [==============================] - 59s 563ms/step - loss: 0.7640 - val_loss: 0.1463\n","Epoch 14/20\n","105/105 [==============================] - 59s 564ms/step - loss: 0.7557 - val_loss: 0.1577\n","Epoch 15/20\n","105/105 [==============================] - 58s 557ms/step - loss: 0.7601 - val_loss: 0.1558\n","Epoch 16/20\n","105/105 [==============================] - 59s 562ms/step - loss: 0.7525 - val_loss: 0.1439\n","Epoch 17/20\n","105/105 [==============================] - 58s 554ms/step - loss: 0.7525 - val_loss: 0.1386\n","Epoch 18/20\n","105/105 [==============================] - 59s 559ms/step - loss: 0.7516 - val_loss: 0.1666\n","Epoch 19/20\n","105/105 [==============================] - 58s 556ms/step - loss: 0.7569 - val_loss: 0.1847\n","Epoch 20/20\n","105/105 [==============================] - 58s 555ms/step - loss: 0.7528 - val_loss: 0.1432\n","Epoch 1/20\n","99/99 [==============================] - 64s 571ms/step - loss: 0.8742 - val_loss: 0.1937\n","Epoch 2/20\n","99/99 [==============================] - 56s 564ms/step - loss: 0.8328 - val_loss: 0.1894\n","Epoch 3/20\n","99/99 [==============================] - 55s 551ms/step - loss: 0.8441 - val_loss: 0.1961\n","Epoch 4/20\n","99/99 [==============================] - 56s 562ms/step - loss: 0.8135 - val_loss: 0.1738\n","Epoch 5/20\n","99/99 [==============================] - 55s 551ms/step - loss: 0.8441 - val_loss: 0.1892\n","Epoch 6/20\n","99/99 [==============================] - 55s 560ms/step - loss: 0.7811 - val_loss: 0.1623\n","Epoch 7/20\n","99/99 [==============================] - 55s 554ms/step - loss: 0.7922 - val_loss: 0.1665\n","Epoch 8/20\n","99/99 [==============================] - 55s 553ms/step - loss: 0.8007 - val_loss: 0.1775\n","Epoch 9/20\n","99/99 [==============================] - 55s 552ms/step - loss: 0.7868 - val_loss: 0.1679\n","Epoch 10/20\n","99/99 [==============================] - 56s 565ms/step - loss: 0.7684 - val_loss: 0.1756\n","Epoch 11/20\n","99/99 [==============================] - 55s 554ms/step - loss: 0.7978 - val_loss: 0.1661\n","Epoch 12/20\n","99/99 [==============================] - 55s 559ms/step - loss: 0.7644 - val_loss: 0.1673\n","Epoch 13/20\n","99/99 [==============================] - 55s 551ms/step - loss: 0.7780 - val_loss: 0.1538\n","Epoch 14/20\n","99/99 [==============================] - 55s 552ms/step - loss: 0.7896 - val_loss: 0.1831\n","Epoch 15/20\n","99/99 [==============================] - 55s 554ms/step - loss: 0.7850 - val_loss: 0.1778\n","Epoch 16/20\n","99/99 [==============================] - 55s 556ms/step - loss: 0.7691 - val_loss: 0.1811\n","Epoch 17/20\n","99/99 [==============================] - 55s 555ms/step - loss: 0.7911 - val_loss: 0.1739\n","Epoch 18/20\n","99/99 [==============================] - 55s 552ms/step - loss: 0.7806 - val_loss: 0.1526\n","Epoch 19/20\n","99/99 [==============================] - 56s 562ms/step - loss: 0.7600 - val_loss: 0.1526\n","Epoch 20/20\n","99/99 [==============================] - 55s 555ms/step - loss: 0.7616 - val_loss: 0.2333\n"]}],"source":["from music21 import *\n","import numpy, os, pretty_midi, glob, pathlib, pickle, random, multiprocessing\n","from multiprocessing import Pool\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization as BatchNorm\n","from keras_self_attention import SeqSelfAttention\n","from keras.utils import np_utils\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from sklearn.model_selection import train_test_split\n","\n","\n","\"\"\"\n","    Prepare the sequences used by the Neural Network.\n","\n","    Args:\n","        music_notes (list): List of notes or chords.\n","        total_unique_notes (int): Total number of unique pitches or chords.\n","\n","    Returns:\n","        tuple: A tuple containing the network input sequences and corresponding network output.\n","\n","\"\"\"\n","def prepare_Note_Sequences(music_notes, total_unique_notes):\n","    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n","    sequence_length = 100\n","\n","    # Get all unique note names and sort them\n","    unique_notes = sorted(set(music_notes))\n","\n","    # Create a dictionary to map notes to integers\n","    note_to_int_mapping = {note: number for number, note in enumerate(unique_notes)}\n","\n","    input_sequences = []\n","    output_sequences = []\n","\n","    # Create input sequences and the corresponding outputs\n","    for i in range(len(music_notes) - sequence_length):\n","        input_sequence = music_notes[i:i + sequence_length]\n","        output_note = music_notes[i + sequence_length]\n","        input_sequences.append([note_to_int_mapping[note] for note in input_sequence])\n","        output_sequences.append(note_to_int_mapping[output_note])\n","\n","    # Reshape the input into a format compatible with LSTM layers and normalize it\n","    normalized_input = numpy.reshape(input_sequences, (len(input_sequences), sequence_length, 1)) / float(total_unique_notes)\n","\n","    # Convert the output to categorical data\n","    categorical_output = np_utils.to_categorical(output_sequences)\n","\n","    return (normalized_input, categorical_output)\n","\n","\"\"\"\n","    Create the structure of the neural network for generating hand movements.\n","\n","    Args:\n","        network_input (ndarray): Input sequences for the network.\n","        n_vocab (int): Total number of unique pitches or chords.\n","        name (str): Name used for loading pre-trained weights.\n","\n","    Returns:\n","        keras.models.Sequential: The compiled model for generating hand movements.\n","\n","\"\"\"\n","def create_Hand_Model(network_input, n_vocab,name):\n","    model = Sequential()\n","    model.add(LSTM(\n","        512,\n","        input_shape=(network_input.shape[1], network_input.shape[2]),\n","        recurrent_dropout=0.3,\n","        return_sequences=True\n","    ))\n","    model.add(SeqSelfAttention(attention_activation='sigmoid'))  # Add attention layer\n","    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n","    model.add(LSTM(512))\n","    model.add(BatchNorm())\n","    model.add(Dropout(0.3))\n","    model.add(Dense(256))\n","    model.add(Activation('relu'))\n","    model.add(BatchNorm())\n","    model.add(Dropout(0.3))\n","    model.add(Dense(n_vocab))\n","    model.add(Activation('softmax'))\n","    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n","    model.load_weights(f'/content/drive/MyDrive/weights-{name}.hdf5')\n","\n","    return model\n","\n","def main():\n","     # Set the directory paths for parts, left hand, and right hand\n","    part_dir = '/content/drive/MyDrive/Parts'\n","    left_dir = 'Left'\n","    right_dir = 'Right'\n","\n","    # Load the right hand notes from the pickle file\n","    with open('/content/drive/MyDrive/Parts/notes-Right.pkl', 'rb') as filepath:\n","        right_notes = pickle.load(filepath)\n","    \n","    # Load the left hand notes from the pickle file\n","    with open('/content/drive/MyDrive/Parts/notes-Left.pkl', 'rb') as filepath:\n","        left_notes = pickle.load(filepath)\n","    \n","    # Calculate the number of unique pitches or chords for the right and left hand\n","    right_vocab = len(set(right_notes))\n","    left_vocab = len(set(left_notes))\n","\n","    # Prepare the sequences for the right hand model\n","    right_hand_input, right_hand_output = prepare_Note_Sequences(right_notes, right_vocab)\n","    right_train_input, right_input_val, right_output_train, right_output_val = train_test_split(right_hand_input, right_hand_output, test_size=0.2, random_state=42)\n","\n","    # Prepare the sequences for the left hand model\n","    left_hand_input, left_hand_output = prepare_Note_Sequences(left_notes, left_vocab)\n","    left_train_input, left_input_val, left_output_train, left_output_val = train_test_split(left_hand_input, left_hand_output, test_size=0.2, random_state=42)\n","\n","    # Create the right hand model\n","    right_model = create_Hand_Model(right_hand_input, right_vocab, 'Right')\n","\n","    # Create the left hand model\n","    left_model = create_Hand_Model(left_hand_input, left_vocab, 'Left')\n","\n","    # Train the right hand model\n","    train(right_model, right_hand_input, right_hand_output, \"Right\",(right_input_val, right_output_val))\n","\n","    # Train the left hand model\n","    train(left_model, left_hand_input, left_hand_output, \"Left\",(left_input_val, left_output_val))\n","\n","\n","\"\"\"\n","    Train the neural network.\n","\n","    Args:\n","        model (keras.models.Sequential): The model to train.\n","        network_input (ndarray): Input sequences for training.\n","        network_output (ndarray): Corresponding network output for training.\n","        name (str): Name used for saving the trained weights.\n","        validation_data (ndarray): validation data\n","\n","    Returns:\n","        None\n","\n","\"\"\"\n","def train(model, network_input, network_output, name, validation_data):\n","    filepath = f\"/content/drive/MyDrive/weights-{name}.hdf5\"\n","    checkpoint = ModelCheckpoint(\n","        filepath,\n","        monitor='loss',\n","        verbose=0,\n","        save_best_only=True,\n","        mode='min'\n","    )\n","    early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1)\n","    callbacks_list = [checkpoint, early_stop]\n","\n","    model.fit(network_input, network_output, epochs=20, batch_size=1408, shuffle=True,\n","              validation_data=validation_data, callbacks=callbacks_list)\n","\n","if __name__ == '__main__':\n","    main()\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"11m7nppRsG55E_R0fp5dLwrK2y8c1ICiX","authorship_tag":"ABX9TyNY8e0XlRSHJPZi09gvw/2g"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}